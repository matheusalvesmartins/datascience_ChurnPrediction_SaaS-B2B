{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheusalvesmartins/datascience_ChurnPrediction_SaaS-B2B/blob/main/ChurnScore_e_Predi%C3%A7%C3%A3o_de_Churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> **Inimigo do Churn: uma análise exploratória by Matt Damon**"
      ],
      "metadata": {
        "id": "2OM4TpxNEkP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#843CFF'><b>INTRODUÇÃO"
      ],
      "metadata": {
        "id": "eRxgtLq-EivQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> **O problema de negócio**\n",
        "\n",
        "<font color='#330870'> Em empresas SaaS B2B, especialmente em plataformas de CRM, o churn de clientes representa um risco significativo tanto para a previsibilidade de receita quanto para a eficiência operacional das equipes de Customer Success. O cancelamento raramente ocorre de forma abrupta; em geral, ele é precedido por sinais comportamentais como redução de uso do sistema, aumento de chamados de suporte, insatisfação expressa em interações com a equipe de CS ou queda em métricas de percepção de valor. No entanto, na ausência de mecanismos estruturados de priorização, esses sinais tendem a ser analisados de forma reativa e subjetiva, dificultando a alocação eficiente do esforço do time de Customer Success nos clientes com maior risco de churn."
      ],
      "metadata": {
        "id": "wWMbSRovEr1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> **Os dados disponíveis**\n",
        "\n",
        "<font color='#330870'> Para enfrentar esse problema, este estudo utiliza dados consolidados em um data lake no Google BigQuery, integrando múltiplas fontes operacionais do ecossistema do CRM. Estão disponíveis informações cadastrais dos clientes, dados financeiros (MRR), métricas de engajamento com o produto, registros de tickets de suporte, chamados de produto, histórico de reuniões com Customer Success — incluindo extração de sinais qualitativos a partir de transcrições — e métricas de satisfação do cliente, como NPS. Esses dados são agregados em nível de cliente e organizados de forma temporal, permitindo a análise de tendências e variações comportamentais ao longo do tempo, fundamentais para a construção de indicadores de risco de churn."
      ],
      "metadata": {
        "id": "59EbQ5wsFpbG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#843CFF'><b>OBJETIVO"
      ],
      "metadata": {
        "id": "wv-PtbjnEzLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> **Objetivo Geral**\n",
        "\n",
        "<font color='#330870'> Desenvolver um churn score baseado em dados comportamentais, operacionais e de satisfação do cliente, capaz de identificar e priorizar clientes com maior risco de churn, apoiando a atuação proativa da equipe de Customer Success na retenção de clientes em um contexto SaaS B2B de CRM."
      ],
      "metadata": {
        "id": "H3K2iVxWEzm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> **Objetivo Específico**\n",
        "\n",
        "* <font color='#330870'>Estruturar uma base analítica integrada, consolidando múltiplas fontes de dados em uma visão única por cliente.\n",
        "\n",
        "* <font color='#330870'>Definir e calcular métricas de engajamento, suporte e relacionamento com Customer Success, com foco em tendências e variações temporais.\n",
        "\n",
        "* <font color='#330870'>Construir um churn score explicável, baseado em regras e pesos interpretáveis, adequado para uso operacional.\n",
        "\n",
        "* <font color='#330870'>Classificar clientes em faixas de risco de churn, viabilizando a priorização de ações preventivas pela equipe de Customer Success.\n",
        "\n",
        "* <font color='#330870'>Estabelecer uma base metodológica que permita a evolução futura do churn score para modelos preditivos supervisionados."
      ],
      "metadata": {
        "id": "HHczYkXbE2zR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#843CFF'><b>DESENVOLVIMENTO"
      ],
      "metadata": {
        "id": "poG7liFCE9KN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00  <font color='#843CFF'><b>PREPARAÇÃO DO AMBIENTE"
      ],
      "metadata": {
        "id": "wp52l8lxRmXN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkvNywvLLcV-"
      },
      "outputs": [],
      "source": [
        "# Importação de bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "f74er2qXM3bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet google-cloud-bigquery pandas-gbq"
      ],
      "metadata": {
        "id": "aNxeCssTN1BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 <font color='#843CFF'><b>CARREGAMENTO DOS DADOS"
      ],
      "metadata": {
        "id": "KCxX2oN-RqIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo os dados do dataset já preparado no GoogleBigQuery\n",
        "client = bigquery.Client(project=\"ploomes-441013\")\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM `ploomes-441013.views_analytics.churn_score_features_v1`\n",
        "\"\"\"\n",
        "\n",
        "df = client.query(query).to_dataframe()"
      ],
      "metadata": {
        "id": "KgO6j2SEN5As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exibindo o cabecalho dos dados\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4Yxc5EoXH4S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando a dimensão do dataset\n",
        "df.shape"
      ],
      "metadata": {
        "id": "ZUtP7p1QRGwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando os tipos de dados e valores nulos\n",
        "df.info()"
      ],
      "metadata": {
        "id": "ixBRgWybOFkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 <font color='#843CFF'><b>EXPLORAÇÃO DOS DADOS"
      ],
      "metadata": {
        "id": "v9OJxMxCRtr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# definindo as variáveis \"variaveis_categoricas\" e \"variaveis_numericas\" a partir do tipo de campo.\n",
        "# se for float64 é numérica, se não é categórica\n",
        "variaveis_categoricas = [var for var in df.columns if df[var].dtype=='O']\n",
        "variaveis_numericas = [var for var in df.columns if df[var].dtype!='O']"
      ],
      "metadata": {
        "id": "7F4RSRvVPsUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando looping para calcular a distribuição percentual para cada variável categórica\n",
        "for coluna in variaveis_categoricas:\n",
        "  print(f'Distribuição percentual para {coluna}')\n",
        "  print(df[coluna].value_counts(normalize=True))\n",
        "  print()"
      ],
      "metadata": {
        "id": "r8vclrKMP_pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando looping para plotar gráfico de barras horizontais da distribuição das variáveis categóricas\n",
        "for coluna in variaveis_categoricas:\n",
        "  df[coluna].value_counts().sort_values(ascending=True).plot(kind='barh', figsize=(8,12), rot=0, color='purple')\n",
        "  plt.xlabel('Frequência')\n",
        "  plt.ylabel(coluna)\n",
        "  plt.title(f'Distribuição de {coluna}')\n",
        "  plt.show()\n",
        "  print()"
      ],
      "metadata": {
        "id": "IYlbwPeSQOc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 <font color='#843CFF'><b>CHURN SCORE"
      ],
      "metadata": {
        "id": "xakt8ki8R2iH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> O **churn score** é um indicador composto que tem como objetivo **estimar o risco relativo de cancelamento de um cliente** a partir da análise de sinais comportamentais, operacionais e de percepção de valor observados ao longo do tempo. A metodologia adotada neste trabalho baseia-se em uma abordagem heurística e explicável, inspirada em modelos de lead scoring, na qual diferentes dimensões do relacionamento do cliente com o produto e com a empresa — como engajamento com o sistema, volume e tendência de chamados de suporte, interações com a equipe de Customer Success e métricas de satisfação (NPS) — são transformadas em regras de pontuação. Cada regra reflete um padrão historicamente associado a maior risco de churn, atribuindo pesos proporcionais à severidade do sinal identificado. O score final resulta da soma dessas pontuações, normalizado em uma escala de 0 a 100, permitindo a classificação dos clientes em faixas de risco e viabilizando sua utilização tanto como ferramenta operacional de priorização quanto como base para evoluções futuras em modelos preditivos supervisionados."
      ],
      "metadata": {
        "id": "qMzPqddpIOei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> A abordagem de churn score adotada neste estudo está alinhada com a literatura recente sobre predição de churn em contextos B2B e SaaS, que aponta o comportamento de uso do produto, o histórico de interações de suporte e a percepção de valor do cliente como antecedentes importantes do cancelamento (RAMIREZ et al., 2024; SANCHES; POSSEBOM; AYLON, 2025). Estudos recentes destacam que o churn, especialmente em modelos SaaS, raramente é um evento abrupto, sendo precedido por mudanças graduais em padrões de engajamento, aumento de atrito operacional e deterioração da satisfação do cliente, o que justifica o uso de métricas agregadas e baseadas em tendências temporais, em vez de indicadores pontuais (MARTIN, 2024). Além disso, trabalhos contemporâneos reforçam a importância de modelos explicáveis e orientados a risco, capazes de apoiar decisões operacionais, como a priorização de clientes pela equipe de Customer Success, mesmo antes da aplicação de modelos preditivos supervisionados (KIMITEI, 2025; DE ALWIS et al., 2025). Nesse contexto, o churn score funciona como uma medida composta de risco, integrando sinais quantitativos e qualitativos para fornecer uma estimativa interpretável do risco relativo de churn, consistente com práticas recomendadas na literatura recente sobre churn em ambientes B2B/SaaS.\n",
        "\n",
        "---\n",
        "\n",
        "> RAMIREZ, J. S. et al. Incorporating usage data for B2B churn prediction modeling. Journal of Business Analytics, 2024. Disponível em: https://www.sciencedirect.com/science/article/abs/pii/S0019850124000865\n",
        ". Acesso em: 29 dez. 2025.\n",
        "\n",
        "> MARTIN, E. Predicting Customer Churn at a SaaS B2B Company. Dissertação (MSc) — [instituição], 2024. Disponível em: https://www.diva-portal.org/smash/get/diva2%3A1901072/FULLTEXT01.pdf\n",
        ". Acesso em: 29 dez. 2025.\n",
        "\n",
        "> SANCHES, H. E.; POSSEBOM, A. T.; AYLON, L. B. R. Churn prediction for SaaS company with machine learning. International Journal of Data Science and Analytics, 2025. Disponível em: https://revistas.usp.br/rai/article/download/239160/215694/771744\n",
        ". Acesso em: 29 dez. 2025.\n",
        "\n",
        "> KIMITEI, S. Predictability & explainability of survival analysis in churn prediction. Journal of Risk Modeling and Interpretation, 2025. Disponível em: https://link.springer.com/article/10.1057/s41270-025-00450-2\n",
        ". Acesso em: 29 dez. 2025.\n",
        "\n",
        "> DE ALWIS, S. et al. Explainability, risk modeling, and segmentation for churn prediction. arXiv preprint, 2025. Disponível em: https://arxiv.org/pdf/2510.11604\n",
        ". Acesso em: 29 dez. 2025.\n"
      ],
      "metadata": {
        "id": "PbOhrCsEKCJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 03-01 <font color='#330870'><b> Calculando o Churn Score"
      ],
      "metadata": {
        "id": "4dZu8QI_0h-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Calculando o ChurnScore"
      ],
      "metadata": {
        "id": "4zZnF2LQjEAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_backup = df.copy()"
      ],
      "metadata": {
        "id": "OyJkksBQaq3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df_backup.copy()"
      ],
      "metadata": {
        "id": "V0E5JBTadTx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_backup.Billing_PaganteAtivo.value_counts()"
      ],
      "metadata": {
        "id": "lIIWwfdYbu4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==========================================================\n",
        "# 0) (IMPORTANTE) Remover qualquer resíduo de cálculo anterior\n",
        "# ==========================================================\n",
        "# Garante que não existe \"acúmulo\" por reexecuções do notebook\n",
        "cols_reset = [\n",
        "    \"churn_score_engajamento\",\n",
        "    \"churn_score_suporte\",\n",
        "    \"churn_score_satisfacao\",\n",
        "    \"churn_score\",\n",
        "    \"churn_risk\",\n",
        "    \"flag_nps_missing\",\n",
        "    \"flag_qoq_users_missing\",\n",
        "    \"flag_tickets_qoq_missing\",\n",
        "]\n",
        "for c in cols_reset:\n",
        "    if c in df.columns:\n",
        "        df.drop(columns=[c], inplace=True)\n",
        "\n",
        "# =========================\n",
        "# 1) Tipagem numérica (sem destruir campos categóricos/booleanos)\n",
        "# =========================\n",
        "non_numeric_cols = [\n",
        "    \"Nome\",\n",
        "    \"CS_EstagioJornada\",\n",
        "    \"ADM_TipoImplementacao\",\n",
        "    \"MOC\",\n",
        "    \"ADM_ClassificacaoPosVendas\",\n",
        "    \"Status\",\n",
        "    \"DataCriacao_Date\",\n",
        "    \"ADM_DataAtivacao_Date\",\n",
        "    \"Billing_PaganteAtivo\",  # <<< importante: não converter aqui\n",
        "]\n",
        "\n",
        "numeric_cols = df.columns.difference(non_numeric_cols)\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# Normalizar Billing_PaganteAtivo para 0/1 (mantém rastreável e modelável)\n",
        "if \"Billing_PaganteAtivo\" in df.columns:\n",
        "    s = df[\"Billing_PaganteAtivo\"]\n",
        "\n",
        "    # se já vier booleano, converte direto\n",
        "    if s.dtype == bool:\n",
        "        df[\"Billing_PaganteAtivo\"] = s.astype(int)\n",
        "    else:\n",
        "        # trata strings comuns\n",
        "        norm = s.astype(str).str.strip().str.lower()\n",
        "        df[\"Billing_PaganteAtivo\"] = np.where(\n",
        "            norm.isin([\"1\", \"true\", \"t\", \"sim\", \"s\", \"yes\", \"y\", \"ativo\", \"pagante\", \"pago\"]),\n",
        "            1,\n",
        "            np.where(\n",
        "                norm.isin([\"0\", \"false\", \"f\", \"nao\", \"não\", \"n\", \"no\", \"inativo\", \"free\", \"trial\", \"gratuito\"]),\n",
        "                0,\n",
        "                np.nan  # caso desconhecido\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 2) Flags auxiliares (missing != neutro)\n",
        "# =========================\n",
        "df[\"flag_nps_missing\"] = df[\"NPS_AvgLastYear\"].isna().astype(int)\n",
        "df[\"flag_qoq_users_missing\"] = df[\"Engage_QOQ_UsersAtivos\"].isna().astype(int)\n",
        "df[\"flag_tickets_qoq_missing\"] = df[\"Tickets_QOQ_TicketsMonthly\"].isna().astype(int)\n",
        "\n",
        "# =========================\n",
        "# 3) Inicializar scores parciais + total (ZERANDO DE FATO)\n",
        "# =========================\n",
        "df[\"churn_score_engajamento\"] = 0\n",
        "df[\"churn_score_suporte\"] = 0\n",
        "df[\"churn_score_satisfacao\"] = 0\n",
        "df[\"churn_score\"] = 0\n",
        "\n",
        "# ==========================================================\n",
        "# 4) Engajamento (rebalanceado, com desvio padrão como tolerância)\n",
        "# ==========================================================\n",
        "def rel_tol(avg_col, std_col):\n",
        "    avg = df[avg_col].astype(float)\n",
        "    std = df[std_col].astype(float)\n",
        "    tol = std / avg.replace(0, np.nan)\n",
        "    return tol.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "def drop_from_qoq(qoq_col):\n",
        "    qoq = df[qoq_col].astype(float)\n",
        "    drop = (1 - qoq).clip(lower=0)  # só penaliza queda (QoQ<1)\n",
        "    return drop.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# -------------------------\n",
        "# 4.1 UsersAtivos\n",
        "# -------------------------\n",
        "users_drop = drop_from_qoq(\"Engage_QOQ_UsersAtivos\")\n",
        "users_tol  = rel_tol(\"Engage_Avg_UsersAtivos\", \"Engage_StDev_UsersAtivos\")\n",
        "users_excess = (users_drop - users_tol).where(users_tol.notna() & users_drop.notna())\n",
        "\n",
        "df.loc[(users_excess > 0) & (users_excess <= 0.20), \"churn_score_engajamento\"] += 5\n",
        "df.loc[(users_excess > 0.20), \"churn_score_engajamento\"] += 10\n",
        "\n",
        "# Missing Users QoQ: não pontua (explicitamente)\n",
        "df.loc[df[\"flag_qoq_users_missing\"] == 1, \"churn_score_engajamento\"] += 0\n",
        "\n",
        "# -------------------------\n",
        "# 4.2 DealsMovimentados\n",
        "# -------------------------\n",
        "deals_drop = drop_from_qoq(\"Engage_QOQ_DealsMovimentados\")\n",
        "deals_tol  = rel_tol(\"Engage_Avg_DealsMovimentados\", \"Engage_StDev_DealsMovimentados\")\n",
        "deals_excess = (deals_drop - deals_tol).where(deals_tol.notna() & deals_drop.notna())\n",
        "\n",
        "df.loc[(deals_excess > 0) & (deals_excess <= 0.30), \"churn_score_engajamento\"] += 5\n",
        "df.loc[(deals_excess > 0.30), \"churn_score_engajamento\"] += 10\n",
        "\n",
        "# -------------------------\n",
        "# 4.3 PropostasCriadas\n",
        "# -------------------------\n",
        "props_drop = drop_from_qoq(\"Engage_QOQ_PropostasCriadas\")\n",
        "props_tol  = rel_tol(\"Engage_Avg_PropostasCriadas\", \"Engage_StDev_PropostasCriadas\")\n",
        "props_excess = (props_drop - props_tol).where(props_tol.notna() & props_drop.notna())\n",
        "\n",
        "df.loc[(props_excess > 0) & (props_excess <= 0.30), \"churn_score_engajamento\"] += 5\n",
        "df.loc[(props_excess > 0.30), \"churn_score_engajamento\"] += 10\n",
        "\n",
        "# -------------------------\n",
        "# 4.4 TasksFinalizadas\n",
        "# -------------------------\n",
        "tasks_drop = drop_from_qoq(\"Engage_QOQ_TasksFinalizadas\")\n",
        "tasks_tol  = rel_tol(\"Engage_Avg_TasksFinalizadas\", \"Engage_StDev_TasksFinalizadas\")\n",
        "tasks_excess = (tasks_drop - tasks_tol).where(tasks_tol.notna() & tasks_drop.notna())\n",
        "\n",
        "df.loc[(tasks_excess > 0) & (tasks_excess <= 0.30), \"churn_score_engajamento\"] += 5\n",
        "df.loc[(tasks_excess > 0.30), \"churn_score_engajamento\"] += 10\n",
        "\n",
        "# ==========================================================\n",
        "# 5) Suporte / Produto\n",
        "# ==========================================================\n",
        "df.loc[df[\"Tickets_QOQ_TicketsMonthly\"] > 1.5, \"churn_score_suporte\"] += 15\n",
        "df.loc[\n",
        "    (df[\"Tickets_QOQ_TicketsMonthly\"] > 1.2) &\n",
        "    (df[\"Tickets_QOQ_TicketsMonthly\"] <= 1.5),\n",
        "    \"churn_score_suporte\"\n",
        "] += 8\n",
        "\n",
        "df.loc[df[\"Chamados_QOQ_ChamadosMonthly\"] > 1.3, \"churn_score_suporte\"] += 10\n",
        "\n",
        "# Missing tickets QoQ: não pontua\n",
        "df.loc[df[\"flag_tickets_qoq_missing\"] == 1, \"churn_score_suporte\"] += 0\n",
        "\n",
        "# ==========================================================\n",
        "# 6) Satisfação (com override opcional)\n",
        "# ==========================================================\n",
        "df.loc[df[\"ReuniaoCS_MentionChurn\"] > 0, \"churn_score_satisfacao\"] += 30\n",
        "\n",
        "df.loc[\n",
        "    df[\"ReuniaoCS_FeedbackNegativo\"] > df[\"ReuniaoCS_FeedbackPositivo\"],\n",
        "    \"churn_score_satisfacao\"\n",
        "] += 10\n",
        "\n",
        "df.loc[df[\"NPS_AvgLastYear\"] < 7, \"churn_score_satisfacao\"] += 5\n",
        "df.loc[df[\"NPS_QOQ\"] < 1, \"churn_score_satisfacao\"] += 5\n",
        "\n",
        "# Missing NPS: não pontua\n",
        "df.loc[df[\"flag_nps_missing\"] == 1, \"churn_score_satisfacao\"] += 0\n",
        "\n",
        "# ==========================================================\n",
        "# 7) Score total\n",
        "# ==========================================================\n",
        "df[\"churn_score\"] = (\n",
        "    df[\"churn_score_engajamento\"] +\n",
        "    df[\"churn_score_suporte\"] +\n",
        "    df[\"churn_score_satisfacao\"]\n",
        ").clip(0, 100)\n",
        "\n",
        "# ==========================================================\n",
        "# 8) churn_risk RECOMPUTADO do ZERO (sobrescreve sempre)\n",
        "# ==========================================================\n",
        "def churn_risk(score):\n",
        "    if score >= 50:\n",
        "        return \"Alto\"\n",
        "    elif score >= 30:\n",
        "        return \"Médio\"\n",
        "    else:\n",
        "        return \"Baixo\"\n",
        "\n",
        "df[\"churn_risk\"] = df[\"churn_score\"].apply(churn_risk)\n",
        "\n",
        "# =========================\n",
        "# 10) Quick view\n",
        "# =========================\n",
        "df.sort_values(\"churn_score\", ascending=False).head(15)[\n",
        "    [\n",
        "        \"Nome\",\n",
        "        \"churn_score\",\n",
        "        \"churn_risk\",\n",
        "        \"churn_score_engajamento\",\n",
        "        \"churn_score_suporte\",\n",
        "        \"churn_score_satisfacao\",\n",
        "        \"Billing_PaganteAtivo\",\n",
        "        \"Engage_QOQ_UsersAtivos\",\n",
        "        \"Engage_StDev_UsersAtivos\",\n",
        "        \"Engage_QOQ_DealsMovimentados\",\n",
        "        \"Engage_StDev_DealsMovimentados\",\n",
        "        \"Engage_QOQ_PropostasCriadas\",\n",
        "        \"Engage_StDev_PropostasCriadas\",\n",
        "        \"Engage_QOQ_TasksFinalizadas\",\n",
        "        \"Engage_StDev_TasksFinalizadas\",\n",
        "        \"Tickets_QOQ_TicketsMonthly\",\n",
        "        \"Chamados_QOQ_ChamadosMonthly\",\n",
        "        \"ReuniaoCS_MentionChurn\",\n",
        "        \"NPS_AvgLastYear\",\n",
        "        \"NPS_QOQ\"\n",
        "    ]\n",
        "]\n"
      ],
      "metadata": {
        "id": "GA5QPXJoUY5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "WPDxGt3OZ--1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> **Componentes do Churn Score.**\n",
        "\n",
        "<font color='#330870'>O churn score proposto é composto por três dimensões complementares.\n",
        "\n",
        "* <font color='#330870'>**Engajamento**: avalia a variação do uso do produto ao longo do tempo, considerando a quantidade de usuários ativos, o volume de negócios (deals) movimentados, a quantidade de propostas criadas e o número de tarefas finalizadas, sempre comparando a variação entre trimestres com a volatilidade histórica de cada métrica para evitar penalizações por oscilações naturais.\n",
        "* <font color='#330870'>**Suporte**: mede o nível de atrito operacional a partir da variação na abertura de tickets de suporte e chamados de produto, comparando o trimestre atual com o trimestre anterior, sob a premissa de que aumentos anormais indicam dificuldades recorrentes ou falhas de adoção.\n",
        "* <font color='#330870'>**Satisfação**: captura sinais de percepção de valor e risco explícito, combinando a variação do NPS ao longo do tempo com evidências qualitativas extraídas das reuniões de Customer Success, como menções diretas a churn e predominância de feedbacks negativos, permitindo identificar riscos que não são necessariamente refletidos apenas em métricas de uso ou suporte."
      ],
      "metadata": {
        "id": "d2tC6EeAjKss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 03-02 <font color='#330870'><b> Análise do Churn Score"
      ],
      "metadata": {
        "id": "RNqw3Ti20pdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## pegando dados para plotagem do gráfico\n"
      ],
      "metadata": {
        "id": "5QaTwigDaF4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Churn Score com toda a base de clientes"
      ],
      "metadata": {
        "id": "wXcEKfKg0xXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# -------------------------\n",
        "# 0) Garantir tipos\n",
        "# -------------------------\n",
        "df[\"CS_MensalidadeAtual_num\"] = pd.to_numeric(df[\"CS_MensalidadeAtual\"], errors=\"coerce\").fillna(0)\n",
        "df[\"churn_score\"] = pd.to_numeric(df[\"churn_score\"], errors=\"coerce\").fillna(0)\n",
        "df[\"churn_score_engajamento\"] = pd.to_numeric(df[\"churn_score_engajamento\"], errors=\"coerce\").fillna(0)\n",
        "df[\"churn_score_suporte\"] = pd.to_numeric(df[\"churn_score_suporte\"], errors=\"coerce\").fillna(0)\n",
        "df[\"churn_score_satisfacao\"] = pd.to_numeric(df[\"churn_score_satisfacao\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Percentuais por cliente (componentes como % do total)\n",
        "# -------------------------\n",
        "total = df[\"churn_score\"].replace(0, np.nan)\n",
        "\n",
        "df[\"eng_pct\"] = (df[\"churn_score_engajamento\"] / total) * 100\n",
        "df[\"sup_pct\"] = (df[\"churn_score_suporte\"] / total) * 100\n",
        "df[\"sat_pct\"] = (df[\"churn_score_satisfacao\"] / total) * 100\n",
        "\n",
        "df[[\"eng_pct\", \"sup_pct\", \"sat_pct\"]] = (\n",
        "    df[[\"eng_pct\", \"sup_pct\", \"sat_pct\"]].fillna(0).clip(0, 100)\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 2) Arrays do gráfico (1 trace único = hover sempre correto)\n",
        "# -------------------------\n",
        "x = df[\"churn_score_engajamento\"].to_numpy()\n",
        "y = df[\"churn_score_suporte\"].to_numpy()\n",
        "z = df[\"churn_score_satisfacao\"].to_numpy()\n",
        "\n",
        "x_max = float(np.nanmax(x)) if len(x) else 0.0\n",
        "y_max = float(np.nanmax(y)) if len(y) else 0.0\n",
        "z_max = float(np.nanmax(z)) if len(z) else 0.0\n",
        "\n",
        "# Cores por ponto (paleta fixa)\n",
        "color_map = {\"Alto\": \"red\", \"Médio\": \"yellow\", \"Baixo\": \"green\"}\n",
        "point_colors = df[\"churn_risk\"].map(color_map).fillna(\"gray\").to_numpy()\n",
        "\n",
        "# 1ª linha do hover: \"PartnersId - Nome\"\n",
        "df[\"hover_id_nome\"] = df[\"PartnersId\"].astype(str) + \" - \" + df[\"Nome\"].astype(str)\n",
        "\n",
        "# customdata por ponto (linha-a-linha)\n",
        "customdata = np.column_stack([\n",
        "    df[\"hover_id_nome\"].fillna(\"\").to_numpy(),        # 0 (PartnersId - Nome)\n",
        "    df[\"CS_MensalidadeAtual_num\"].to_numpy(),         # 1\n",
        "    df[\"churn_score\"].to_numpy(),                     # 2\n",
        "\n",
        "    df[\"churn_score_engajamento\"].to_numpy(),         # 3\n",
        "    df[\"eng_pct\"].to_numpy(),                         # 4\n",
        "\n",
        "    df[\"churn_score_suporte\"].to_numpy(),             # 5\n",
        "    df[\"sup_pct\"].to_numpy(),                         # 6\n",
        "\n",
        "    df[\"churn_score_satisfacao\"].to_numpy(),          # 7\n",
        "    df[\"sat_pct\"].to_numpy(),                         # 8\n",
        "])\n",
        "\n",
        "# -------------------------\n",
        "# 3) Figura\n",
        "# -------------------------\n",
        "n_clients = int(df.shape[0])\n",
        "title_text = (\n",
        "    \"Distribuição 3D dos clientes por componentes do Churn Score\"\n",
        "    f\"<br><sup>Total de clientes representados = {n_clients}</sup>\"\n",
        ")\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter3d(\n",
        "            x=x, y=y, z=z,\n",
        "            mode=\"markers\",\n",
        "            marker=dict(size=5, opacity=0.85, color=point_colors),\n",
        "            customdata=customdata,\n",
        "            hovertemplate=(\n",
        "                \"<b>%{customdata[0]}</b><br>\"\n",
        "                \"Mensalidade (CS): R$ %{customdata[1]:,.2f}<br><br>\"\n",
        "                \"<b>Churn Score (Total):</b> %{customdata[2]:.1f}%<br><br>\"\n",
        "                \"<b>Componentes (pontos e % do total):</b><br>\"\n",
        "                \"Engajamento: %{customdata[3]:.0f} pts (%{customdata[4]:.1f}%)<br>\"\n",
        "                \"Suporte: %{customdata[5]:.0f} pts (%{customdata[6]:.1f}%)<br>\"\n",
        "                \"Satisfação: %{customdata[7]:.0f} pts (%{customdata[8]:.1f}%)<br>\"\n",
        "                \"<extra></extra>\"\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=title_text,\n",
        "    height=740,\n",
        "    scene=dict(\n",
        "        xaxis=dict(title=\"Engajamento (pontos)\", range=[0, x_max]),\n",
        "        yaxis=dict(title=\"Suporte (pontos)\", range=[0, y_max]),\n",
        "        zaxis=dict(title=\"Satisfação (pontos)\", range=[0, z_max]),\n",
        "        aspectmode=\"cube\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "QbyMKWfzP_Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### DOWNLOAD DO HTML DO GRÁFICO 3D\n",
        "import plotly.io as pio\n",
        "\n",
        "pio.write_html(\n",
        "    fig,\n",
        "    file=\"churn_3d.html\",\n",
        "    include_plotlyjs=True,\n",
        "    full_html=True,\n",
        "    auto_open=False\n",
        ")"
      ],
      "metadata": {
        "id": "i9AquKXSOjtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# =========================\n",
        "# Parâmetros\n",
        "# =========================\n",
        "TOP_N = 30  # <<< ajuste manualmente aqui\n",
        "color_map = {\"Alto\": \"red\", \"Médio\": \"yellow\", \"Baixo\": \"green\"}\n",
        "\n",
        "# =========================\n",
        "# Preparar dados\n",
        "# =========================\n",
        "bar = df.copy()\n",
        "\n",
        "# Tipagem\n",
        "bar[\"CS_MensalidadeAtual_num\"] = pd.to_numeric(bar[\"CS_MensalidadeAtual\"], errors=\"coerce\").fillna(0)\n",
        "bar[\"churn_score\"] = pd.to_numeric(bar[\"churn_score\"], errors=\"coerce\").fillna(0)\n",
        "bar[\"churn_score_engajamento\"] = pd.to_numeric(bar[\"churn_score_engajamento\"], errors=\"coerce\").fillna(0)\n",
        "bar[\"churn_score_suporte\"] = pd.to_numeric(bar[\"churn_score_suporte\"], errors=\"coerce\").fillna(0)\n",
        "bar[\"churn_score_satisfacao\"] = pd.to_numeric(bar[\"churn_score_satisfacao\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "bar[\"label_cliente\"] = bar[\"PartnersId\"].astype(str) + \" - \" + bar[\"Nome\"].astype(str)\n",
        "\n",
        "# Percentuais por cliente\n",
        "total = bar[\"churn_score\"].replace(0, np.nan)\n",
        "bar[\"eng_pct\"] = (bar[\"churn_score_engajamento\"] / total) * 100\n",
        "bar[\"sup_pct\"] = (bar[\"churn_score_suporte\"] / total) * 100\n",
        "bar[\"sat_pct\"] = (bar[\"churn_score_satisfacao\"] / total) * 100\n",
        "bar[[\"eng_pct\", \"sup_pct\", \"sat_pct\"]] = bar[[\"eng_pct\", \"sup_pct\", \"sat_pct\"]].fillna(0).clip(0, 100)\n",
        "\n",
        "# Top N\n",
        "bar = bar.sort_values(\"churn_score\", ascending=False).head(TOP_N).copy()\n",
        "\n",
        "# =========================\n",
        "# Gráfico de barras horizontal\n",
        "# =========================\n",
        "fig = px.bar(\n",
        "    bar,\n",
        "    x=\"churn_score\",\n",
        "    y=\"label_cliente\",\n",
        "    orientation=\"h\",\n",
        "    color=\"churn_risk\",\n",
        "    color_discrete_map=color_map,\n",
        "    text=bar[\"churn_score\"].round(1),  # <<< rótulo do dado\n",
        "    title=f\"Top {len(bar)} clientes por Churn Score\"\n",
        ")\n",
        "\n",
        "# Rótulos fora da barra\n",
        "fig.update_traces(\n",
        "    textposition=\"outside\",\n",
        "    cliponaxis=False,  # <<< evita cortar o texto\n",
        "    hovertemplate=(\n",
        "        \"<b>%{y}</b><br>\"\n",
        "        \"Mensalidade (CS): R$ %{customdata[0]:,.2f}<br><br>\"\n",
        "        \"<b>Churn Score (Total):</b> %{customdata[1]:.1f}%<br><br>\"\n",
        "        \"<b>Componentes (pontos e % do total):</b><br>\"\n",
        "        \"Engajamento: %{customdata[2]:.0f} pts (%{customdata[3]:.1f}%)<br>\"\n",
        "        \"Suporte: %{customdata[4]:.0f} pts (%{customdata[5]:.1f}%)<br>\"\n",
        "        \"Satisfação: %{customdata[6]:.0f} pts (%{customdata[7]:.1f}%)<br>\"\n",
        "        \"<extra></extra>\"\n",
        "    ),\n",
        "    customdata=np.column_stack([\n",
        "        bar[\"CS_MensalidadeAtual_num\"].to_numpy(),      # 0\n",
        "        bar[\"churn_score\"].to_numpy(),                  # 1\n",
        "        bar[\"churn_score_engajamento\"].to_numpy(),      # 2\n",
        "        bar[\"eng_pct\"].to_numpy(),                      # 3\n",
        "        bar[\"churn_score_suporte\"].to_numpy(),          # 4\n",
        "        bar[\"sup_pct\"].to_numpy(),                      # 5\n",
        "        bar[\"churn_score_satisfacao\"].to_numpy(),       # 6\n",
        "        bar[\"sat_pct\"].to_numpy(),                      # 7\n",
        "    ])\n",
        ")\n",
        "\n",
        "# Layout final\n",
        "fig.update_layout(\n",
        "    height=max(520, 22 * len(bar)),   # responsivo ao TOP_N\n",
        "    yaxis=dict(title=\"Cliente\", autorange=\"reversed\"),\n",
        "    xaxis=dict(title=\"Churn Score (Total, %)\", range=[0, 105]),  # espaço p/ rótulo externo\n",
        "    legend_title_text=\"Risco de Churn\",\n",
        "    margin=dict(l=40, r=40, t=70, b=40),\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4fZCYg_xYmO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### exibindo valores de billing_pagante ativo\n",
        "df.Billing_PaganteAtivo.value_counts()"
      ],
      "metadata": {
        "id": "H9vTztgIZY3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Churn Score com a base de clientes ATIVOS"
      ],
      "metadata": {
        "id": "WuiNx9Si04Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### VERSÃO COM BASE NO DATASET DE TREINAMENTO"
      ],
      "metadata": {
        "id": "RnzAtMzNhiKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# =========================\n",
        "# Parâmetros\n",
        "# =========================\n",
        "TOP_N = 30  # <<< ajuste manualmente aqui\n",
        "color_map = {\"Alto\": \"red\", \"Médio\": \"yellow\", \"Baixo\": \"green\"}\n",
        "\n",
        "# =========================\n",
        "# Preparar dados\n",
        "# =========================\n",
        "# filtrando billing_pagante ativo\n",
        "bar = df[df['Billing_PaganteAtivo'] == 1].copy()\n",
        "\n",
        "# Tipagem\n",
        "bar[\"CS_MensalidadeAtual_num\"] = pd.to_numeric(bar[\"CS_MensalidadeAtual\"], errors=\"coerce\").fillna(0)\n",
        "bar[\"churn_score\"] = pd.to_numeric(bar[\"churn_score\"], errors=\"coerce\").fillna(0)\n",
        "bar[\"churn_score_engajamento\"] = pd.to_numeric(bar[\"churn_score_engajamento\"], errors=\"coerce\").fillna(0)\n",
        "bar[\"churn_score_suporte\"] = pd.to_numeric(bar[\"churn_score_suporte\"], errors=\"coerce\").fillna(0)\n",
        "bar[\"churn_score_satisfacao\"] = pd.to_numeric(bar[\"churn_score_satisfacao\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "bar[\"label_cliente\"] = bar[\"PartnersId\"].astype(str) + \" - \" + bar[\"Nome\"].astype(str)\n",
        "\n",
        "# Percentuais por cliente\n",
        "total = bar[\"churn_score\"].replace(0, np.nan)\n",
        "bar[\"eng_pct\"] = (bar[\"churn_score_engajamento\"] / total) * 100\n",
        "bar[\"sup_pct\"] = (bar[\"churn_score_suporte\"] / total) * 100\n",
        "bar[\"sat_pct\"] = (bar[\"churn_score_satisfacao\"] / total) * 100\n",
        "bar[[\"eng_pct\", \"sup_pct\", \"sat_pct\"]] = bar[[\"eng_pct\", \"sup_pct\", \"sat_pct\"]].fillna(0).clip(0, 100)\n",
        "\n",
        "# Top N\n",
        "bar = bar.sort_values(\"churn_score\", ascending=False).head(TOP_N).copy()\n",
        "\n",
        "# =========================\n",
        "# Gráfico de barras horizontal\n",
        "# =========================\n",
        "fig = px.bar(\n",
        "    bar,\n",
        "    x=\"churn_score\",\n",
        "    y=\"label_cliente\",\n",
        "    orientation=\"h\",\n",
        "    color=\"churn_risk\",\n",
        "    color_discrete_map=color_map,\n",
        "    text=bar[\"churn_score\"].round(1),  # <<< rótulo do dado\n",
        "    title=f\"Top {len(bar)} clientes por Churn Score\"\n",
        ")\n",
        "\n",
        "# Rótulos fora da barra\n",
        "fig.update_traces(\n",
        "    textposition=\"outside\",\n",
        "    cliponaxis=False,  # <<< evita cortar o texto\n",
        "    hovertemplate=(\n",
        "        \"<b>%{y}</b><br>\"\n",
        "        \"Mensalidade (CS): R$ %{customdata[0]:,.2f}<br><br>\"\n",
        "        \"<b>Churn Score (Total):</b> %{customdata[1]:.1f}%<br><br>\"\n",
        "        \"<b>Componentes (pontos e % do total):</b><br>\"\n",
        "        \"Engajamento: %{customdata[2]:.0f} pts (%{customdata[3]:.1f}%)<br>\"\n",
        "        \"Suporte: %{customdata[4]:.0f} pts (%{customdata[5]:.1f}%)<br>\"\n",
        "        \"Satisfação: %{customdata[6]:.0f} pts (%{customdata[7]:.1f}%)<br>\"\n",
        "        \"<extra></extra>\"\n",
        "    ),\n",
        "    customdata=np.column_stack([\n",
        "        bar[\"CS_MensalidadeAtual_num\"].to_numpy(),      # 0\n",
        "        bar[\"churn_score\"].to_numpy(),                  # 1\n",
        "        bar[\"churn_score_engajamento\"].to_numpy(),      # 2\n",
        "        bar[\"eng_pct\"].to_numpy(),                      # 3\n",
        "        bar[\"churn_score_suporte\"].to_numpy(),          # 4\n",
        "        bar[\"sup_pct\"].to_numpy(),                      # 5\n",
        "        bar[\"churn_score_satisfacao\"].to_numpy(),       # 6\n",
        "        bar[\"sat_pct\"].to_numpy(),                      # 7\n",
        "    ])\n",
        ")\n",
        "\n",
        "# Layout final\n",
        "fig.update_layout(\n",
        "    height=max(520, 22 * len(bar)),   # responsivo ao TOP_N\n",
        "    yaxis=dict(title=\"Cliente\", autorange=\"reversed\"),\n",
        "    xaxis=dict(title=\"Churn Score (Total, %)\", range=[0, 105]),  # espaço p/ rótulo externo\n",
        "    legend_title_text=\"Risco de Churn\",\n",
        "    margin=dict(l=40, r=40, t=70, b=40),\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "9V3ykKWgyp_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# criando dataFrame dos clientes ativos\n",
        "df2 = df[df['Billing_PaganteAtivo'] == 1]\n",
        "\n",
        "# -------------------------\n",
        "# 0) Garantir tipos\n",
        "# -------------------------\n",
        "df2[\"CS_MensalidadeAtual_num\"] = pd.to_numeric(df2[\"CS_MensalidadeAtual\"], errors=\"coerce\").fillna(0)\n",
        "df2[\"churn_score\"] = pd.to_numeric(df2[\"churn_score\"], errors=\"coerce\").fillna(0)\n",
        "df2[\"churn_score_engajamento\"] = pd.to_numeric(df2[\"churn_score_engajamento\"], errors=\"coerce\").fillna(0)\n",
        "df2[\"churn_score_suporte\"] = pd.to_numeric(df2[\"churn_score_suporte\"], errors=\"coerce\").fillna(0)\n",
        "df2[\"churn_score_satisfacao\"] = pd.to_numeric(df2[\"churn_score_satisfacao\"], errors=\"coerce\").fillna(0)\n",
        "\n",
        "# -------------------------\n",
        "# 1) Percentuais por cliente (componentes como % do total)\n",
        "# -------------------------\n",
        "total = df2[\"churn_score\"].replace(0, np.nan)\n",
        "\n",
        "df2[\"eng_pct\"] = (df2[\"churn_score_engajamento\"] / total) * 100\n",
        "df2[\"sup_pct\"] = (df2[\"churn_score_suporte\"] / total) * 100\n",
        "df2[\"sat_pct\"] = (df2[\"churn_score_satisfacao\"] / total) * 100\n",
        "\n",
        "df2[[\"eng_pct\", \"sup_pct\", \"sat_pct\"]] = (\n",
        "    df2[[\"eng_pct\", \"sup_pct\", \"sat_pct\"]].fillna(0).clip(0, 100)\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 2) Arrays do gráfico (1 trace único = hover sempre correto)\n",
        "# -------------------------\n",
        "x = df2[\"churn_score_engajamento\"].to_numpy()\n",
        "y = df2[\"churn_score_suporte\"].to_numpy()\n",
        "z = df2[\"churn_score_satisfacao\"].to_numpy()\n",
        "\n",
        "x_max = float(np.nanmax(x)) if len(x) else 0.0\n",
        "y_max = float(np.nanmax(y)) if len(y) else 0.0\n",
        "z_max = float(np.nanmax(z)) if len(z) else 0.0\n",
        "\n",
        "# Cores por ponto (paleta fixa)\n",
        "color_map = {\"Alto\": \"red\", \"Médio\": \"yellow\", \"Baixo\": \"green\"}\n",
        "point_colors = df2[\"churn_risk\"].map(color_map).fillna(\"gray\").to_numpy()\n",
        "\n",
        "# 1ª linha do hover: \"PartnersId - Nome\"\n",
        "df2[\"hover_id_nome\"] = df2[\"PartnersId\"].astype(str) + \" - \" + df2[\"Nome\"].astype(str)\n",
        "\n",
        "# customdata por ponto (linha-a-linha)\n",
        "customdata = np.column_stack([\n",
        "    df2[\"hover_id_nome\"].fillna(\"\").to_numpy(),        # 0 (PartnersId - Nome)\n",
        "    df2[\"CS_MensalidadeAtual_num\"].to_numpy(),         # 1\n",
        "    df2[\"churn_score\"].to_numpy(),                     # 2\n",
        "\n",
        "    df2[\"churn_score_engajamento\"].to_numpy(),         # 3\n",
        "    df2[\"eng_pct\"].to_numpy(),                         # 4\n",
        "\n",
        "    df2[\"churn_score_suporte\"].to_numpy(),             # 5\n",
        "    df2[\"sup_pct\"].to_numpy(),                         # 6\n",
        "\n",
        "    df2[\"churn_score_satisfacao\"].to_numpy(),          # 7\n",
        "    df2[\"sat_pct\"].to_numpy(),                         # 8\n",
        "])\n",
        "\n",
        "# -------------------------\n",
        "# 3) Figura\n",
        "# -------------------------\n",
        "n_clients = int(df2.shape[0])\n",
        "title_text = (\n",
        "    \"Distribuição 3D dos clientes por componentes do Churn Score\"\n",
        "    f\"<br><sup>Total de clientes representados = {n_clients}</sup>\"\n",
        ")\n",
        "\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter3d(\n",
        "            x=x, y=y, z=z,\n",
        "            mode=\"markers\",\n",
        "            marker=dict(size=5, opacity=0.85, color=point_colors),\n",
        "            customdata=customdata,\n",
        "            hovertemplate=(\n",
        "                \"<b>%{customdata[0]}</b><br>\"\n",
        "                \"Mensalidade (CS): R$ %{customdata[1]:,.2f}<br><br>\"\n",
        "                \"<b>Churn Score (Total):</b> %{customdata[2]:.1f}%<br><br>\"\n",
        "                \"<b>Componentes (pontos e % do total):</b><br>\"\n",
        "                \"Engajamento: %{customdata[3]:.0f} pts (%{customdata[4]:.1f}%)<br>\"\n",
        "                \"Suporte: %{customdata[5]:.0f} pts (%{customdata[6]:.1f}%)<br>\"\n",
        "                \"Satisfação: %{customdata[7]:.0f} pts (%{customdata[8]:.1f}%)<br>\"\n",
        "                \"<extra></extra>\"\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=title_text,\n",
        "    height=740,\n",
        "    scene=dict(\n",
        "        xaxis=dict(title=\"Engajamento (pontos)\", range=[0, x_max]),\n",
        "        yaxis=dict(title=\"Suporte (pontos)\", range=[0, y_max]),\n",
        "        zaxis=dict(title=\"Satisfação (pontos)\", range=[0, z_max]),\n",
        "        aspectmode=\"cube\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "Til2iQVp0-nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 <font color='#843CFF'><b>PREDIÇÃO DE CHURN"
      ],
      "metadata": {
        "id": "46jFcoybNvdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Agora com um dataset já tratado e com Churn score, vamos consultar dados de clientes que churnaram anteriormente e assim vamos conseguir ter a label de clientes churnados para mesclar com o nosso dataset.\n",
        "\n",
        "<font color='#330870'> A partir desse ponto, poderemos treinar um modelo de machine learning para predição de churn."
      ],
      "metadata": {
        "id": "kqSHJISfPdEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04-00 <font color='#330870'><b> Obtendo a label de Churn"
      ],
      "metadata": {
        "id": "ODwQXW5MQGuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo os dados do dataset clientes_churn\n",
        "client = bigquery.Client(project=\"ploomes-441013\")\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM `ploomes-441013.ploomes.clientes_churn`\n",
        "\"\"\"\n",
        "\n",
        "df_label_churn = client.query(query).to_dataframe()"
      ],
      "metadata": {
        "id": "aPgjBa96Ny5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_churn.head()"
      ],
      "metadata": {
        "id": "1yOmBCU7QVwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_churn.info()"
      ],
      "metadata": {
        "id": "TMQt7yejQY-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_churn_backup = df_label_churn.copy()"
      ],
      "metadata": {
        "id": "BqLfrkZTRA3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_label_churn = df_label_churn_backup.copy()"
      ],
      "metadata": {
        "id": "8qcHKA-4TQJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tratando df_label_churn e mantendo somente os campos PloomesId, PartnersId, _Billing_|_M_s_de_churn, _Adm_|_Estadia_total_em_meses_\n",
        "df_label_churn = df_label_churn[['PloomesId','_Billing_|_M_s_de_churn', '_Adm_|_Estadia_total_em_meses_', 'PartnersId']]\n",
        "\n",
        "df_label_churn.head()"
      ],
      "metadata": {
        "id": "KyVGZL36QbID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removendo os valores onde _Billing_|_M_s_de_churn é vazio, nulo ou NaT\n",
        "df_label_churn = df_label_churn.dropna(subset=['_Billing_|_M_s_de_churn'])\n",
        "df_label_churn.head()"
      ],
      "metadata": {
        "id": "GPaux2jwQ1fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_churn.info()"
      ],
      "metadata": {
        "id": "XoN0HRUSRWa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fazendo a junção de df_label_churn com df em um novo dataframe df_churn\n",
        "# usando df como dataset principal, trazer os valores de \"_Billing_|_M_s_de_churn\" e \"_Adm_|_Estadia_total_em_meses_\" vinculando PloomesId com PloomesId\n",
        "# se não encontrar o par, deixar os valores vazios\n",
        "# incluir uma nova coluna chamada \"churn\" de sim/não. se estiver com o valor de \"_Billing_|_M_s_de_churn\" preenchida, vai ser True, se estiver sem valor é False\n",
        "df_churn = pd.merge(df, df_label_churn, left_on='PloomesId', right_on='PloomesId', how='left')\n",
        "df_churn.head()"
      ],
      "metadata": {
        "id": "70Ybu37HRYkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_churn.info()"
      ],
      "metadata": {
        "id": "vpMllcDPRxF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removendo \"PartnersId_y\"\n",
        "df_churn = df_churn.drop(columns=['PartnersId_y'])\n",
        "\n",
        "# renomeando \"_Billing_|_M_s_de_churn\" para \"data_churn\" e \"_Adm_|_Estadia_total_em_meses_\" para \"estadia_meses\"\n",
        "df_churn = df_churn.rename(columns={'_Billing_|_M_s_de_churn': 'data_churn', '_Adm_|_Estadia_total_em_meses_': 'estadia_churn_meses'})\n",
        "\n",
        "# incluindo a coluna de \"churn\", é vazio então \"True\"\n",
        "df_churn['churn'] = df_churn['data_churn'].notna()\n",
        "\n",
        "df_churn.head()"
      ],
      "metadata": {
        "id": "dNjwANqCSR0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exibindo a proporção da distribuição pelo valor churn\n",
        "df_churn['churn'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "f4xUS66sa9Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removendo MRR_Atual\n",
        "df_churn = df_churn.drop(columns=['MRR_Atual'])"
      ],
      "metadata": {
        "id": "PiE5FlyOTKv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculando a data de estadia real hoje com base em na diferença em meses da data hoje(today) pela data do campo \"ADM_DataAtivacao_Date\"\n",
        "df_churn['estadia_real_meses'] = (pd.to_datetime('today') - pd.to_datetime(df_churn['ADM_DataAtivacao_Date'])).dt.days // 30"
      ],
      "metadata": {
        "id": "wkrtpCkZUyaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04-01 <font color='#330870'><b> Pré-processamento dos dados"
      ],
      "metadata": {
        "id": "_cMk68dhTt6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Considerando os pontos observados na análise exploratória, identificamos a necessidade de tratar os outliers da variável numérica existente no dataset. Portanto, iniciamos o pré-processamento do dataset **removendo os outliers de [CS_MensalidadeAtual]**."
      ],
      "metadata": {
        "id": "8HZXnW9Al1Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## REMOVENDO OUTLIERS\n",
        "\n",
        "# Definindo uma função para remover Outliers de um dataframe com base em uma variável numérica e opcionalmente uma variável categórica\n",
        "def remover_outliers_iqr(df, variavel_num, variavel_cat=None):    # define a função com a variavel_cat como opcional\n",
        "  if variavel_cat is not None:                                 # se a variável categórica for fornecida\n",
        "    df_variavel_cat = pd.DataFrame()                            # cria um dataframe vazio\n",
        "    for categoria in df[variavel_cat].unique():                 # para cada valor fornecido na variável categórica\n",
        "      df_categoria = df[df[variavel_cat] == categoria]            # cria um dataframe com os dados da categoria\n",
        "      Q1 = df_categoria[variavel_num].quantile(0.25)              # calcula o primeiro quartil\n",
        "      Q3 = df_categoria[variavel_num].quantile(0.75)              # calcula o terceiro quartil\n",
        "      IQR = Q3 - Q1                                               # calcula o intervalo interquartil\n",
        "      limite_inferior = Q1 - 1.5 * IQR                            # calcula o limite inferior\n",
        "      limite_superior = Q3 + 1.5 * IQR                            # calcula o limite superior\n",
        "      df_categoria = df_categoria[(df_categoria[variavel_num] >= limite_inferior) & (df_categoria[variavel_num] <= limite_superior)] # remove os outliers\n",
        "      df_variavel_cat = pd.concat([df_variavel_cat, df_categoria]) # concatena os dataframes\n",
        "    return df_variavel_cat                                      # retorna o dataframe com os outliers removidos\n",
        "  else:                                                         # se a variável categórica não for fornecida\n",
        "    Q1 = df[variavel_num].quantile(0.25)                          # calcula o primeiro quartil\n",
        "    Q3 = df[variavel_num].quantile(0.75)                          # calcula o terceiro quartil\n",
        "    IQR = Q3 - Q1                                                 # calcula o intervalo interquartil\n",
        "    limite_inferior = Q1 - 1.5 * IQR                              # calcula o limite inferior\n",
        "    limite_superior = Q3 + 1.5 * IQR                              # calcula o limite superior\n",
        "    df = df[(df[variavel_num] >= limite_inferior) & (df[variavel_num] <= limite_superior)]  # remove os outliers\n",
        "    return df                                                    # retorna o dataframe com os outliers removidos\n",
        "\n",
        "# Removendo os Outliers do Dataframe\n",
        "df_sem_outliers = remover_outliers_iqr(df_churn, 'CS_MensalidadeAtual')\n",
        "\n",
        "# Determinando a dimensão do Dataset após a remoção dos outliers\n",
        "df_sem_outliers.shape"
      ],
      "metadata": {
        "id": "04hcHQxMoVBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sem_outliers.info()"
      ],
      "metadata": {
        "id": "bOk5-vBOUQed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint\n",
        "# copiando o dataset para treinamento\n",
        "df_treinamento = df_sem_outliers.copy()\n",
        "\n",
        "# removendo as colunas desnecessárias\n",
        "df_treinamento = df_treinamento.drop(columns=['PartnersId_x', 'Billing_PaganteAtivo','estadia_churn_meses', 'estadia_real_meses', 'PloomesId', 'Nome', 'DataCriacao_Date', 'ADM_DataAtivacao_Date', 'data_churn'])\n",
        "\n",
        "# exibindo o dataset\n",
        "df_treinamento.head()"
      ],
      "metadata": {
        "id": "iuQUsAigUIPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04-02 <font color='#330870'><b> Separação dos dados de treinamento e teste"
      ],
      "metadata": {
        "id": "30y5MvylY17R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Separamos o conjunto de dados de treinamento e teste com uma proporção de 80% de dados para treinamento e 20% para teste."
      ],
      "metadata": {
        "id": "B63y9TYzY83R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Criar Dataset para treinamento através de uma cópia do dataset sem as variáveis categóricas que serão o atributo alvo\n",
        "X = df_treinamento.drop(['churn'], axis=1).copy()\n",
        "\n",
        "# Criar dataset com uma cópia do dataset original somente com o atributo alvo\n",
        "y = df_treinamento['churn'].copy()\n",
        "\n",
        "# Usando train_test_split para separar o conjunto de dados de teste e treinamento\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "d8pXPSWHYitW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(5)"
      ],
      "metadata": {
        "id": "cFC4wr7SZD_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head(5)"
      ],
      "metadata": {
        "id": "gfz31gEvZGMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Para facilitar o pipeline de classificação, criamos também variáveis para identificar automaticamente as variáveis numéricas e categóricas do dataset de treinamento."
      ],
      "metadata": {
        "id": "fai_3V-RZMx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determinando as colunas categóricas e numéricas do dataset de treinamento\n",
        "categorical = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical = X_train.select_dtypes(include=['number']).columns.tolist()"
      ],
      "metadata": {
        "id": "ZqiW7aSGZIuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explicando os dados utilizados no treinamento\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "DF = X  # ajuste se seu dataframe tiver outro nome\n",
        "N_EXAMPLES = 5\n",
        "OUT_PREFIX = \"data_dictionary\"\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def snake_to_title(s: str) -> str:\n",
        "    s = re.sub(r\"[_\\-]+\", \" \", str(s)).strip()\n",
        "    return re.sub(r\"\\s+\", \" \", s).title()\n",
        "\n",
        "def infer_semantic_group(col: str) -> str:\n",
        "    c = col.lower()\n",
        "\n",
        "    rules = [\n",
        "        (\"Identificação do cliente\", [\"partnersid\", \"ploomesid\", \"accountid\", \"id\", \"nome\", \"label_cliente\", \"customer\"]),\n",
        "        (\"Financeiro / Receita\", [\"mrr\", \"mensalidade\", \"billing\", \"receita\", \"arr\", \"cs_mensalidade\"]),\n",
        "        (\"Engajamento (uso do produto)\", [\"engage\", \"users\", \"ativos\", \"tasks\", \"tarefas\", \"propostas\", \"deals\", \"moviment\"]),\n",
        "        (\"Suporte / Produto\", [\"tickets\", \"chamados\", \"intercom\", \"jira\", \"issue\"]),\n",
        "        (\"Satisfação / Voz do cliente\", [\"nps\", \"csat\", \"feedback\", \"mentionchurn\", \"churn\", \"satisf\"]),\n",
        "        (\"Segmentação / Contexto do cliente\", [\"moc\", \"tipoimplementacao\", \"classificacao\", \"estagiojornada\", \"status\"]),\n",
        "        (\"Datas / Marcos\", [\"data\", \"date\", \"dt\", \"mes\"]),\n",
        "        (\"Scores / Labels (modelagem)\", [\"score\", \"risk\", \"label\", \"target\", \"y_\"]),\n",
        "    ]\n",
        "\n",
        "    for group, keys in rules:\n",
        "        if any(k in c for k in keys):\n",
        "            return group\n",
        "    return \"Outros\"\n",
        "\n",
        "def infer_measure_type(col: str) -> str:\n",
        "    c = col.lower()\n",
        "    if \"qoq\" in c:\n",
        "        return \"Variação (QoQ / razão)\"\n",
        "    if \"avg\" in c or \"mean\" in c:\n",
        "        return \"Média\"\n",
        "    if \"stdev\" in c or \"std\" in c:\n",
        "        return \"Volatilidade (desvio padrão)\"\n",
        "    if \"count\" in c or \"qtde\" in c or \"quant\" in c:\n",
        "        return \"Contagem\"\n",
        "    if \"pct\" in c or \"percent\" in c:\n",
        "        return \"Percentual\"\n",
        "    if \"mrr\" in c or \"mensalidade\" in c or \"billing\" in c:\n",
        "        return \"Valor monetário\"\n",
        "    if \"date\" in c or \"data\" in c or \"mes\" in c:\n",
        "        return \"Data/Tempo\"\n",
        "    return \"Atributo / métrica\"\n",
        "\n",
        "def pandas_dtype_label(series: pd.Series) -> str:\n",
        "    dt = series.dtype\n",
        "    if pd.api.types.is_integer_dtype(dt): return \"inteiro\"\n",
        "    if pd.api.types.is_float_dtype(dt): return \"decimal\"\n",
        "    if pd.api.types.is_bool_dtype(dt): return \"booleano\"\n",
        "    if pd.api.types.is_datetime64_any_dtype(dt): return \"data/hora\"\n",
        "    return \"texto\"\n",
        "\n",
        "def try_parse_dates(s: pd.Series) -> bool:\n",
        "    # tenta reconhecer colunas que são datas em texto\n",
        "    if pd.api.types.is_datetime64_any_dtype(s.dtype):\n",
        "        return True\n",
        "    if s.dtype == \"object\":\n",
        "        sample = s.dropna().astype(str).head(50)\n",
        "        if sample.empty:\n",
        "            return False\n",
        "        parsed = pd.to_datetime(sample, errors=\"coerce\", utc=False)\n",
        "        return parsed.notna().mean() > 0.7\n",
        "    return False\n",
        "\n",
        "def summarize_numeric(s: pd.Series):\n",
        "    s2 = pd.to_numeric(s, errors=\"coerce\")\n",
        "    if s2.dropna().empty:\n",
        "        return {\"min\": None, \"p50\": None, \"max\": None}\n",
        "    return {\n",
        "        \"min\": float(np.nanmin(s2)),\n",
        "        \"p50\": float(np.nanpercentile(s2, 50)),\n",
        "        \"max\": float(np.nanmax(s2)),\n",
        "    }\n",
        "\n",
        "def safe_examples(s: pd.Series, n=N_EXAMPLES):\n",
        "    vals = s.dropna().unique()\n",
        "    vals = vals[:n]\n",
        "    return \", \".join([str(v) for v in vals])\n",
        "\n",
        "# =========================\n",
        "# Build dictionary\n",
        "# =========================\n",
        "rows = []\n",
        "for col in DF.columns:\n",
        "    s = DF[col]\n",
        "    non_null = int(s.notna().sum())\n",
        "    total = int(len(s))\n",
        "    missing_pct = round((1 - non_null / total) * 100, 2) if total else 0.0\n",
        "\n",
        "    group = infer_semantic_group(col)\n",
        "    measure_type = infer_measure_type(col)\n",
        "\n",
        "    # tipo inferido (mais semântico do que dtype puro)\n",
        "    semantic_dtype = \"data/hora\" if try_parse_dates(s) else pandas_dtype_label(s)\n",
        "\n",
        "    # exemplos\n",
        "    examples = safe_examples(s, N_EXAMPLES)\n",
        "\n",
        "    # estatísticas se numérico\n",
        "    num_stats = {\"min\": None, \"p50\": None, \"max\": None}\n",
        "    if pd.api.types.is_numeric_dtype(s.dtype):\n",
        "        num_stats = summarize_numeric(s)\n",
        "    else:\n",
        "        # tenta detectar numérico mesmo sendo texto (ex: \"4.0\")\n",
        "        coerced = pd.to_numeric(s, errors=\"coerce\")\n",
        "        if coerced.notna().mean() > 0.8:\n",
        "            num_stats = summarize_numeric(coerced)\n",
        "            semantic_dtype = \"decimal\"\n",
        "\n",
        "    # descrição automática curta\n",
        "    # (você pode editar depois manualmente para uma versão “final”)\n",
        "    description = (\n",
        "        f\"{snake_to_title(col)}. \"\n",
        "        f\"Grupo: {group}. Tipo: {measure_type}. \"\n",
        "        f\"Armazena um campo de {semantic_dtype} relacionado a {group.lower()}.\"\n",
        "    )\n",
        "\n",
        "    rows.append({\n",
        "        \"field_name\": col,\n",
        "        \"field_title\": snake_to_title(col),\n",
        "        \"group\": group,\n",
        "        \"measure_type\": measure_type,\n",
        "        \"data_type_inferred\": semantic_dtype,\n",
        "        \"missing_%\": missing_pct,\n",
        "        \"examples\": examples,\n",
        "        \"min\": num_stats[\"min\"],\n",
        "        \"p50\": num_stats[\"p50\"],\n",
        "        \"max\": num_stats[\"max\"],\n",
        "        \"auto_description\": description,\n",
        "    })\n",
        "\n",
        "dictionary_df = pd.DataFrame(rows).sort_values([\"group\", \"field_name\"]).reset_index(drop=True)\n",
        "\n",
        "# =========================\n",
        "# Export outputs\n",
        "# =========================\n",
        "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "csv_path = f\"{OUT_PREFIX}_{ts}.csv\"\n",
        "md_path = f\"{OUT_PREFIX}_{ts}.md\"\n",
        "\n",
        "dictionary_df.to_csv(csv_path, index=False)\n",
        "\n",
        "# Markdown simples para colar em docs\n",
        "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"# Data Dictionary (gerado automaticamente)\\n\\n\")\n",
        "    f.write(dictionary_df.to_markdown(index=False))\n",
        "\n",
        "print(\"Arquivos gerados:\")\n",
        "print(\" -\", csv_path)\n",
        "print(\" -\", md_path)\n",
        "\n",
        "dictionary_df.head(20)"
      ],
      "metadata": {
        "id": "8jLuEnucsJj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04-03 <font color='#330870'><b> Construção do modelo"
      ],
      "metadata": {
        "id": "L4a1b2DZZSzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 04-03-01 Construindo o pipeline"
      ],
      "metadata": {
        "id": "WqOzXKLUZcth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importando o classificador RandomForest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# importando o classificador DecisionTree\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "QwW4Rl3IZK3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Definindo o pré-processador:"
      ],
      "metadata": {
        "id": "666WUZ8ifdiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas de aprendizado de máquina\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, TargetEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# criar variável que define quais pré-processamentos serão feitos\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical),\n",
        "        ('cat', TargetEncoder(), categorical)\n",
        "    ])"
      ],
      "metadata": {
        "id": "18ME4TD9peuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Definindo os pipelines classificadores para modelo:"
      ],
      "metadata": {
        "id": "iK7FfhIrfgwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# criando um pipeline para cada classificador (DecisionTree, RandomForest e GaussianNaive Bayes)\n",
        "classificador_dt = Pipeline(\n",
        "    steps=[\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier())\n",
        "    ]\n",
        "    )\n",
        "\n",
        "classificador_rf = Pipeline(\n",
        "    steps=[\n",
        "    ('preprocessing', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "    ]\n",
        "    )"
      ],
      "metadata": {
        "id": "ehUtDKxLx1Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyMfi7JcZ25d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 04-03-02 Treinando o modelo e fazendo as predições"
      ],
      "metadata": {
        "id": "hsSlcaLCyqU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Após a definição do pipeline classificador, utilizamos os dados de treinamento, representados pelos dataset X_train e y_train, para realizar o treinamento do modelo."
      ],
      "metadata": {
        "id": "jn6jgleCqLHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color='#330870'> Classificador Decision Tree"
      ],
      "metadata": {
        "id": "OqVHJ3J3y1qJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Treinando o modelo classificador com **Decision Tree**"
      ],
      "metadata": {
        "id": "DL30tLznzg59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo supervisionado (ou seja, possuo a classe alvo em y) para cada classificador\n",
        "classificador_dt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "-C3HD6YCYrhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Com o modelo classificador treinado, podemos então fazer as predições para os dados de teste e de treino."
      ],
      "metadata": {
        "id": "eLM2djYFqa75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer as predições para os dados de teste\n",
        "y_pred_test_dt = classificador_dt.predict(X_test)\n",
        "\n",
        "# Fazer as predições para os dados de treino\n",
        "y_pred_train_dt = classificador_dt.predict(X_train)"
      ],
      "metadata": {
        "id": "KSRaTrQeYwct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color='#330870'>Classificador Random Forest"
      ],
      "metadata": {
        "id": "yc8ICIWRy8a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Treinando o modelo classificador com **Random Forest**"
      ],
      "metadata": {
        "id": "5OzjL-JdzAOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo supervisionado (ou seja, possuo a classe alvo em y) para cada classificador\n",
        "classificador_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "59zVvxLNzAtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Com o modelo classificador treinado, podemos então fazer as predições para os dados de teste e de treino."
      ],
      "metadata": {
        "id": "R7rjsaezz2st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer as predições para os dados de teste\n",
        "y_pred_test_rf = classificador_rf.predict(X_test)\n",
        "\n",
        "# Fazer as predições para os dados de treino\n",
        "y_pred_train_rf = classificador_rf.predict(X_train)"
      ],
      "metadata": {
        "id": "kkQPbcA3z3J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04-04 <font color='#330870'><b> Avaliação da performance dos modelos"
      ],
      "metadata": {
        "id": "k7U_H1MEnRO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Agora com o modelo treinado e as predições feitas, podemos avaliar a performance do modelo. Inicialmente faremos a avaliação com o ClassificationReport e a Matriz de Confusão, a fim de obter a acurácia do modelo, sua precissão e recall."
      ],
      "metadata": {
        "id": "m5UjU_ZRqobr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# printando a avaliação classification report para cada classificador\n",
        "print(\"Classification Report - Decision Tree:\")\n",
        "print(classification_report(y_test, y_pred_test_dt))\n",
        "print(\"\")\n",
        "print(\"\\nClassification Report - Random Forest:\")\n",
        "print(classification_report(y_test, y_pred_test_rf))"
      ],
      "metadata": {
        "id": "wez_7ONu0Vyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerando a matriz de confusão para cada modelo classificador\n",
        "cm_dt = confusion_matrix(y_test, y_pred_test_dt)\n",
        "cm_rf = confusion_matrix(y_test, y_pred_test_rf)\n",
        "\n",
        "# plotando as matrizes de confusão\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=classificador_dt.classes_)\n",
        "disp.plot(cmap='Purples')\n",
        "plt.title('Matriz de Confusão - Decision Tree')\n",
        "plt.show()\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=classificador_rf.classes_)\n",
        "disp.plot(cmap='Purples')\n",
        "plt.title('Matriz de Confusão - Random Forest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ubDrrsNw0xhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checando a proporção de y_test values para cada classificador\n",
        "\n",
        "print(\"Proporção de y_test values para cada classificador:\")\n",
        "print(\"\")\n",
        "print(\"Decision Tree:\", y_test.value_counts(normalize=True))\n",
        "print(\"\")\n",
        "print(\"Random Forest:\", y_test.value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "_NoPwM-HbOcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04-05 <font color='#330870'><b> Validação do modelo"
      ],
      "metadata": {
        "id": "Roj11EjInXZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> Para fazer uma validação final do modelo, garantindo que ele é capaz de generalizar para novos dados e que não caiu em overfitting ou underfitting."
      ],
      "metadata": {
        "id": "Yq6NtPTOsIpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> A curva de aprendizado permite diagnosticar visualmente esse comportamento e tomar decisões sobre ajustes no modelo, como poda, ajuste de profundidade ou até uso de outros algoritmos mais robustos.\n",
        "\n",
        "<font color='#330870'> Portanto, plotamos abaixo a curva de aprendizado dos modelos de classificação."
      ],
      "metadata": {
        "id": "zDtWQjZutEOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando e plotando a curva de aprendizado para cada classificador\n",
        "from sklearn.model_selection import learning_curve"
      ],
      "metadata": {
        "id": "tflP0wYJ1xlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculando a curva de aprendizado para DecisionTree\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    classificador_dt,                         # modelo de classificação\n",
        "    X,                                        # dados de treinamento\n",
        "    y,                                        # dados alvo\n",
        "    cv=10,                                    # validação cruzada com 10 folds\n",
        "    scoring='accuracy',                       # métrica de avaliação\n",
        "    n_jobs=-1,                                # número de núcleos da CPU utilizados (-1 = todos disponíveis)\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10)     # proporção dos conjuntos de treino\n",
        ")\n",
        "\n",
        "train_mean = train_scores.mean(axis=1)\n",
        "test_mean = val_scores.mean(axis=1)\n",
        "\n",
        "# Plotando\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.ylim(0, 1.1)\n",
        "\n",
        "# Linha de treino\n",
        "line1, = plt.plot(train_sizes, train_mean, marker='o', label=\"Treino\", color='purple')\n",
        "for x, y_val in zip(train_sizes, train_mean):\n",
        "    plt.text(x, y_val + 0.02, f\"{y_val:.2f}\", color=line1.get_color(), fontsize=9, ha='center')\n",
        "\n",
        "# Linha de validação\n",
        "line2, = plt.plot(train_sizes, test_mean, marker='s', label=\"Validação\", color='green')\n",
        "for x, y_val in zip(train_sizes, test_mean):\n",
        "    plt.text(x, y_val + 0.02, f\"{y_val:.2f}\", color=line2.get_color(), fontsize=9, ha='center')\n",
        "\n",
        "plt.xlabel(\"Tamanho do conjunto de treino\")\n",
        "plt.ylabel(\"Acurácia\")\n",
        "plt.title(\"Curva de Aprendizado - Decision Tree\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0OuyQfg1q2Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculando a curva de aprendizado para RandomForest\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    classificador_rf,                         # modelo de classificação\n",
        "    X,                                        # dados de treinamento\n",
        "    y,                                        # dados alvo\n",
        "    cv=10,                                    # validação cruzada com 10 folds\n",
        "    scoring='accuracy',                       # métrica de avaliação\n",
        "    n_jobs=-1,                                # número de núcleos da CPU utilizados (-1 = todos disponíveis)\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10)     # proporção dos conjuntos de treino\n",
        ")\n",
        "\n",
        "train_mean = train_scores.mean(axis=1)\n",
        "test_mean = val_scores.mean(axis=1)\n",
        "\n",
        "# Plotando\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.ylim(0, 1.1)\n",
        "\n",
        "# Linha de treino\n",
        "line1, = plt.plot(train_sizes, train_mean, marker='o', label=\"Treino\", color='purple')\n",
        "for x, y_val in zip(train_sizes, train_mean):\n",
        "    plt.text(x, y_val + 0.02, f\"{y_val:.2f}\", color=line1.get_color(), fontsize=9, ha='center')\n",
        "\n",
        "# Linha de validação\n",
        "line2, = plt.plot(train_sizes, test_mean, marker='s', label=\"Validação\", color='green')\n",
        "for x, y_val in zip(train_sizes, test_mean):\n",
        "    plt.text(x, y_val + 0.02, f\"{y_val:.2f}\", color=line2.get_color(), fontsize=9, ha='center')\n",
        "\n",
        "plt.xlabel(\"Tamanho do conjunto de treino\")\n",
        "plt.ylabel(\"Acurácia\")\n",
        "plt.title(\"Curva de Aprendizado - RandomForest\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-3hSuIpSr69r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04-06~08 hiperparametrização, threshold, performance modelo hiperparametrizado ????"
      ],
      "metadata": {
        "id": "5Xs3TeLqbYm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 04-09  <font color='#330870'>  Explicabilidade do modelo"
      ],
      "metadata": {
        "id": "xzjO6GVKMtXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='#330870'> A explicabilidade em modelos de machine learning é fundamental para garantir confiança, transparência e usabilidade prática, principalmente em contextos de tomada de decisão empresarial. Entender como o modelo toma suas decisões permite que usuários não técnicos validem se o raciocínio da máquina está alinhado com o conhecimento de negócio. Além disso, essa análise ajuda a identificar possíveis vieses, variáveis irrelevantes ou até oportunidades para melhorias no modelo. Técnicas como SHAP são especialmente úteis, pois avaliam o impacto individual de cada feature nas predições, ajudando a avaliar o comportamento do modelo tanto de forma agregada (importância média) quanto em instâncias específicas."
      ],
      "metadata": {
        "id": "Enpw28NelqLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Carrega o modelo (pipeline completo)\n",
        "modelo = classificador_rf  # seu pipeline\n",
        "\n",
        "#copiando somente 10 registros do df_treinamento\n",
        "#df_explica = df_treinamento.iloc[:10].copy()\n",
        "df_explica = df_treinamento.copy()\n",
        "\n",
        "# Obtém apenas as colunas usadas no modelo\n",
        "colunas_utilizadas = modelo.feature_names_in_\n",
        "df_modelo = df_explica[colunas_utilizadas]\n",
        "\n",
        "\n",
        "# Supondo que seu Pipeline tenha steps nomeados como:\n",
        "# 'preprocessing' => ColumnTransformer\n",
        "# 'classifier'    => RandomForest ou outro modelo\n",
        "preprocessador = modelo.named_steps[\"preprocessing\"]\n",
        "modelo_final = modelo.named_steps[\"classifier\"]\n",
        "\n",
        "# Aplica transformação\n",
        "X_preprocessed = preprocessador.transform(df_modelo)\n",
        "\n",
        "# Obtém os nomes corretos das colunas após transformação\n",
        "feature_names = preprocessador.get_feature_names_out()\n",
        "\n",
        "df_preprocessado = pd.DataFrame(X_preprocessed, columns=feature_names)\n",
        "\n",
        "\n",
        "# --- Feature Importance (se disponível)\n",
        "if hasattr(modelo_final, \"feature_importances_\"):\n",
        "    importances = modelo_final.feature_importances_\n",
        "    importance_df = pd.DataFrame({\n",
        "        \"Feature\": feature_names,\n",
        "        \"Importance\": importances\n",
        "    }).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color=\"purple\")\n",
        "    plt.xlabel(\"Importância\")\n",
        "    plt.title(\"Importância das Features no Modelo\")\n",
        "    #exibindo os rótulos dos dados\n",
        "    for i, v in enumerate(importance_df[\"Importance\"]):\n",
        "        plt.text(v, i, str(round(v, 3)), color='black', fontweight='bold')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# --- SHAP\n",
        "explainer = shap.Explainer(modelo_final.predict_proba, df_preprocessado)\n",
        "shap_values = explainer(df_preprocessado)\n",
        "\n",
        "# Selecionar índice da classe positiva (ex: 'True')\n",
        "classes = modelo_final.classes_\n",
        "print(\"Classes disponíveis:\", classes)\n",
        "\n",
        "# Ajuste aqui caso 'Ganha' esteja em outra posição\n",
        "idx_classe_positiva = list(classes).index(True)\n",
        "\n",
        "# Seleciona os shap_values apenas da classe positiva\n",
        "shap_values_pos = shap_values[..., idx_classe_positiva]\n",
        "\n",
        "# Gráfico SHAP de barras\n",
        "shap.plots.bar(shap_values_pos, max_display=10)\n",
        "\n",
        "# Gráfico SHAP beeswarm\n",
        "shap.plots.beeswarm(shap_values_pos)"
      ],
      "metadata": {
        "id": "rJ1wJ3n1MxVK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}